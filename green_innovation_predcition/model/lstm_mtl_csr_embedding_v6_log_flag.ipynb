{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dfdf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "df = pd.read_csv(\"../data/csr_embeddings_leq2019_filled_flag_citation_count_cpc_lagged.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d79a3a",
   "metadata": {},
   "source": [
    "## Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bf111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed) # ÊéßÂà∂ Python ÂÖßÂª∫ÁöÑ random Ê®°ÁµÑÔºà‰æãÂ¶Ç random.shuffle()„ÄÅrandom.randint()Ôºâ„ÄÇ\n",
    "    np.random.seed(seed) # ÊéßÂà∂ NumPy ÊâÄÊúâÈö®Ê©üÊìç‰ΩúÔºà‰æãÂ¶Ç np.random.rand()„ÄÅnp.random.shuffle()Ôºâ„ÄÇ\n",
    "    torch.manual_seed(seed) # ÊéßÂà∂ CPU ‰∏ä PyTorch ÁöÑÈö®Ê©üÊÄßÔºà‰æãÂ¶Ç torch.rand()Ôºâ„ÄÇ\n",
    "    torch.cuda.manual_seed(seed)  # for CUDA\n",
    "    torch.cuda.manual_seed_all(seed)  # for multi-GPU\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True  # Âº∑Âà∂‰ΩøÁî® deterministicÔºàÁ¢∫ÂÆöÊÄßÔºâÁâàÊú¨ÁöÑ CuDNN Êìç‰ΩúÔºåÈÅøÂÖçÊüê‰∫õ kernel ÈÄ†ÊàêÈùû‰∏ÄËá¥ÊÄßËº∏Âá∫„ÄÇ\n",
    "    torch.backends.cudnn.benchmark = False     # ÈóúÈñâ CuDNN Ê†πÊìöËº∏ÂÖ•Ëá™ÂãïÈÅ∏ÊúÄ‰Ω≥ÊºîÁÆóÊ≥ïÁöÑÊ©üÂà∂ÔºåÈÅøÂÖçÂõ†ÈÅ∏Âà∞‰∏çÂêå kernel ËÄåÊúâ‰∏çÂêåÁµêÊûú„ÄÇ\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dbd4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72989931",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78ec7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindowDatasetMax5Flag(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, company_list, max_len=5):\n",
    "        self.samples = []\n",
    "\n",
    "        df = df[df['ticker'].isin(company_list)].copy()\n",
    "\n",
    "        for company_id, group in df.groupby('ticker'):\n",
    "            group = group.sort_values('year').reset_index(drop=True)\n",
    "\n",
    "            years = group['year'].values\n",
    "            imputed_flags = group['is_imputed'].values\n",
    "            x_all = torch.tensor(group[[f'dim_{i}' for i in range(1024)]].values, dtype=torch.float32)\n",
    "            y_all = torch.tensor(group[['patents_count', 'total_5yr_forward_citations']].values, dtype=torch.float32)\n",
    "            y_all = torch.log1p(y_all)\n",
    "\n",
    "            for end in range(len(group)):\n",
    "                if imputed_flags[end]:  # Â¶ÇÊûúË©≤Á≠ÜÊòØ imputedÔºåË∑≥ÈÅé‰∏çÂÅöÁÇ∫ target\n",
    "                    continue\n",
    "\n",
    "                start = max(0, end - max_len + 1)\n",
    "                x_seq = x_all[start:end+1]\n",
    "                y_seq = y_all[end]\n",
    "                y_year = years[end]\n",
    "                self.samples.append({\n",
    "                    'x_seq': x_seq,\n",
    "                    'y_seq': y_seq,\n",
    "                    'ticker': company_id,\n",
    "                    'y_year': y_year,\n",
    "                    'index': f\"{company_id}_{years[start]}_{y_year}\"\n",
    "                })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        return sample['x_seq'], sample['y_seq'], sample['ticker'], sample['y_year'], sample['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd10278f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a89f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_MTL_Stepwise(nn.Module):\n",
    "    def __init__(self, input_dim=1024, hidden_dim=256, head_dim=32):\n",
    "        super().__init__()\n",
    "        self.lstm_cell = nn.LSTMCell(input_dim, hidden_dim)\n",
    "\n",
    "        # Shared Sequential Layer\n",
    "        self.shared_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, head_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "        \n",
    "        # Head for patents_count\n",
    "        self.head_count = nn.Sequential(\n",
    "            nn.Linear(head_dim, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Head for citations\n",
    "        self.head_citation = nn.Sequential(\n",
    "            nn.Linear(head_dim, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, lengths):  \n",
    "        B, T_max, D = x.shape\n",
    "        \n",
    "        h = torch.zeros(B, 256, device=x.device)\n",
    "        c = torch.zeros(B, 256, device=x.device)\n",
    "        \n",
    "        # ÈÄêÊ≠•Á¥ØÁ©çÊâÄÊúâÊôÇÈñìÊ≠•ÁöÑ hÔºåÊúÄÂæåÊ†πÊìöÊØèÁ≠ÜË≥áÊñôÁöÑÁúüÂØ¶Èï∑Â∫¶Âæû h_all ‰∏≠ÂãïÊÖãÂèñÂá∫Â∞çÊáâÁöÑÊúÄÂæåÊúâÊïà hÔºàËÄåÈùûÁõ¥Êé•Âèñ T_maxÔºâÔºåÈÅøÂÖç padding ÂΩ±Èüø\n",
    "        h_list = []\n",
    "\n",
    "        for t in range(T_max):\n",
    "            h, c = self.lstm_cell(x[:, t, :], (h, c))\n",
    "            h_list.append(h.unsqueeze(1))  # [B, 1, H]\n",
    "\n",
    "        h_all = torch.cat(h_list, dim=1)  # [B, T_max, H]\n",
    "\n",
    "        # ‰ΩøÁî® batch Á¥¢ÂºïÁõ¥Êé•ÂèñÂá∫ÊØèÁ≠ÜË≥áÊñôÊúÄÂæåÊúâÊïàÊ≠•È©üÁöÑ h\n",
    "        batch_indices = torch.arange(B, device=x.device)\n",
    "        last_h = h_all[batch_indices, lengths - 1, :]  # [B, H]\n",
    "\n",
    "        # ÂÖàÁ∂ìÈÅé shared head 256 ‚ûî 32\n",
    "        shared_out = self.shared_head(last_h)  # [B, 32]\n",
    "\n",
    "        y1 = self.head_count(shared_out)\n",
    "        y2 = self.head_citation(shared_out)\n",
    "\n",
    "        return torch.cat([y1, y2], dim=1)  # [B, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500d2029",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45fe545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Metrics (expm1 to reverse log1p) ---\n",
    "def compute_metrics(y_pred, y_true):\n",
    "    y_pred = torch.expm1(y_pred).cpu().numpy()\n",
    "    y_true = torch.expm1(y_true).cpu().numpy()\n",
    "    metrics = {}\n",
    "\n",
    "    # Âä†‰∏ä round\n",
    "    # y_pred = np.round(y_pred)\n",
    "    # y_true = np.round(y_true)\n",
    "    \n",
    "    for i, name in enumerate([\"count\", \"citation\"]):\n",
    "        y_p, y_t = y_pred[:, i], y_true[:, i]\n",
    "        mse = np.mean((y_p - y_t) ** 2)\n",
    "        mae = np.mean(np.abs(y_p - y_t))\n",
    "        rmse = np.sqrt(mse)\n",
    "        smape = np.mean(2 * np.abs(y_p - y_t) / (np.abs(y_p) + np.abs(y_t) + 1e-8))*100\n",
    "        metrics[name] = {\"MSE\": mse, \"MAE\": mae, \"RMSE\": rmse, \"SMAPE\": smape}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a0f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_folds_and_epochs(df, folds, epochs=3):\n",
    "    for fold_id, (train_coms, test_coms) in enumerate(folds):\n",
    "        print(f\"\\n====== Inspect Fold {fold_id+1} ======\")\n",
    "\n",
    "        # Dataset   \n",
    "        train_dataset = SlidingWindowDatasetMax5Flag(df, train_coms)\n",
    "        test_dataset = SlidingWindowDatasetMax5Flag(df, test_coms)\n",
    "\n",
    "        # DataLoader\n",
    "        train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=lambda x: x)\n",
    "        val_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=lambda x: x)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"\\n--- Fold {fold_id+1} Epoch {epoch+1} [Train] ---\")\n",
    "            company_counter = 0\n",
    "            sample_counter = 0\n",
    "            for batch in train_loader:\n",
    "                _, _, tickers, y_years, indices = zip(*batch)\n",
    "                print(f\"Company: {tickers[0]} | Samples: {len(indices)} | Years: {min(y_years)}-{max(y_years)}\")\n",
    "                print(f\"  Indices: {indices}\")\n",
    "                company_counter += 1\n",
    "                sample_counter += len(indices)\n",
    "            print(f\"===> [Train Summary] Companies: {company_counter} | Total Samples: {sample_counter}\")\n",
    "\n",
    "            print(f\"\\n--- Fold {fold_id+1} Epoch {epoch+1} [Validation] ---\")\n",
    "            company_counter = 0\n",
    "            sample_counter = 0\n",
    "            for batch in val_loader:\n",
    "                _, _, tickers, y_years, indices = zip(*batch)\n",
    "                print(f\"Company: {tickers[0]} | Samples: {len(indices)} | Years: {min(y_years)}-{max(y_years)}\")\n",
    "                print(f\"  Indices: {indices}\")\n",
    "                company_counter += 1\n",
    "                sample_counter += len(indices)\n",
    "            print(f\"===> [Validation Summary] Companies: {company_counter} | Total Samples: {sample_counter}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6b90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect_folds_and_epochs(df, folds=5, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee4b969",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0226b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSEPunishLoss(nn.Module):\n",
    "    def __init__(self, alpha=1.0, punish_mode='', return_each=False):\n",
    "        \"\"\"\n",
    "        :param alpha: Êá≤ÁΩ∞È†ÖÊ¨äÈáç\n",
    "        :param punish_mode: 'abs', 'square', 'binary', 'huber', 'ratio', 'threshold'\n",
    "        :param return_each: ÊòØÂê¶ÂõûÂÇ≥ count loss Âíå citation loss\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.alpha = alpha\n",
    "        self.punish_mode = punish_mode\n",
    "        self.return_each = return_each\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        pred_count, pred_citation = preds[:, 0], preds[:, 1]\n",
    "        true_count, true_citation = targets[:, 0], targets[:, 1]\n",
    "\n",
    "        loss_count = self.mse(pred_count, true_count)\n",
    "        loss_citation = self.mse(pred_citation, true_citation)\n",
    "        loss_total = loss_count + loss_citation\n",
    "\n",
    "        # Initialize punishment\n",
    "        punishment = 0.0\n",
    "\n",
    "        if self.punish_mode:\n",
    "            mask = (true_count == 0)\n",
    "            if mask.sum() > 0:\n",
    "                if self.punish_mode == 'abs':\n",
    "                    punishment = torch.sum(torch.abs(pred_citation[mask]))\n",
    "                elif self.punish_mode == 'square':\n",
    "                    punishment = torch.sum((pred_citation[mask]) ** 2)\n",
    "                elif self.punish_mode == 'binary':\n",
    "                    punishment = torch.sum((pred_citation[mask] > 1e-4).float())\n",
    "                elif self.punish_mode == 'huber':\n",
    "                    punishment = nn.functional.smooth_l1_loss(\n",
    "                        pred_citation[mask],\n",
    "                        torch.zeros_like(pred_citation[mask]),\n",
    "                        reduction='sum'\n",
    "                    )\n",
    "                elif self.punish_mode == 'ratio':\n",
    "                    safe_count = true_count + 1e-6\n",
    "                    ratio = pred_citation / safe_count\n",
    "                    punishment = torch.sum(ratio[mask])\n",
    "                elif self.punish_mode == 'threshold':\n",
    "                    threshold = 1.0\n",
    "                    over = torch.clamp(pred_citation[mask] - threshold, min=0)\n",
    "                    punishment = torch.sum(over)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported punish_mode: {self.punish_mode}\")\n",
    "\n",
    "        loss_total = loss_total + self.alpha * punishment\n",
    "\n",
    "        if self.return_each:\n",
    "            return loss_total, loss_count.item(), loss_citation.item()\n",
    "        else:\n",
    "            return loss_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43d6638",
   "metadata": {},
   "source": [
    "## StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b49f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "company_df = df.groupby('ticker')[['patents_count', 'total_5yr_forward_citations']].mean().reset_index()\n",
    "\n",
    "# Step 1: Âª∫Á´ã count ÊòØÂê¶ÁÇ∫ 0 ÁöÑ flag\n",
    "company_df['has_patents'] = (company_df['patents_count'] > 0).astype(int)\n",
    "\n",
    "# Step 2: Â∞ç citation ÈÄ≤Ë°åÂàÜÁÆ±ÔºàÂè™Â∞çÊúâÁî¢Âá∫ÁöÑÂÖ¨Âè∏ÂàÜÔºâ\n",
    "bins = [-1, 0, 10, 50, 200, np.inf]\n",
    "company_df['citation_bin'] = pd.cut(company_df['total_5yr_forward_citations'], bins=bins, labels=False)\n",
    "\n",
    "# Step 3: Âª∫Á´ãÁ∂úÂêà stratify Ê®ôÁ±§\n",
    "# Ê≤íÊúâÁî¢Âá∫ÁöÑÂÖ¨Âè∏Áµ±‰∏ÄÁÇ∫ 0ÔºåÊúâÁî¢Âá∫ËÄÖÊ†πÊìö citation_bin ÂàÜÂ±§\n",
    "company_df['stratify_label'] = company_df.apply(\n",
    "    lambda row: 0 if row['has_patents'] == 0 else row['citation_bin'] + 1,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "stratified_kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "folds = []\n",
    "for train_idx, test_idx in stratified_kf.split(company_df['ticker'], company_df['stratify_label']):\n",
    "    train_coms = company_df.iloc[train_idx]['ticker'].values\n",
    "    test_coms = company_df.iloc[test_idx]['ticker'].values\n",
    "    folds.append((train_coms, test_coms))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c60320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (_, test_coms) in enumerate(folds):\n",
    "    sub_df = df[df['ticker'].isin(test_coms)]\n",
    "    sample_size = len(sub_df)\n",
    "\n",
    "    # Citation Áµ±Ë®à\n",
    "    mean_cit = sub_df['total_5yr_forward_citations'].mean()\n",
    "    std_cit = sub_df['total_5yr_forward_citations'].std()\n",
    "    max_cit = sub_df['total_5yr_forward_citations'].max()\n",
    "\n",
    "    # Count Áµ±Ë®à\n",
    "    mean_cnt = sub_df['patents_count'].mean()\n",
    "    std_cnt = sub_df['patents_count'].std()\n",
    "    max_cnt = sub_df['patents_count'].max()\n",
    "\n",
    "    # ÁÑ°Â∞àÂà©ÂÖ¨Âè∏ÊØî‰æã\n",
    "    company_level = sub_df.groupby('ticker')['patents_count'].sum().reset_index()\n",
    "    no_patent_ratio = (company_level['patents_count'] == 0).mean() * 100\n",
    "\n",
    "    print(f\"[Fold {i+1}]\")\n",
    "    print(f\"  Sample Size: {sample_size}\")\n",
    "    print(f\"  Citation ‚Üí mean: {mean_cit:.2f} | std: {std_cit:.2f} | max: {max_cit:.2f}\")\n",
    "    print(f\"  Count    ‚Üí mean: {mean_cnt:.2f} | std: {std_cnt:.2f} | max: {max_cnt:.2f}\")\n",
    "    print(f\"  % Companies with NO patents: {no_patent_ratio:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c32c288",
   "metadata": {},
   "source": [
    "## Evaluate best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f087f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_best_model(model, val_loader, fold_id, best_epoch):\n",
    "    \"\"\"\n",
    "    Evaluate the best model on the validation set, returning predictions, true labels, and metadata.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_y = []\n",
    "    val_meta_info = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_id, batch in enumerate(val_loader):\n",
    "            x_seqs, y_seqs, tickers, y_years, indices = zip(*batch)\n",
    "            lengths = torch.tensor([x.shape[0] for x in x_seqs]).to(next(model.parameters()).device)\n",
    "            x_seqs = pad_sequence(x_seqs, batch_first=True).to(next(model.parameters()).device)\n",
    "            y_seqs = torch.stack(y_seqs).to(next(model.parameters()).device)\n",
    "\n",
    "            preds = model(x_seqs, lengths)\n",
    "\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_y.append(y_seqs.cpu())\n",
    "\n",
    "            for i, index in enumerate(indices):\n",
    "                val_meta_info.append({\n",
    "                    \"fold\": fold_id + 1,\n",
    "                    \"epoch\": best_epoch + 1,\n",
    "                    \"batch\": batch_id + 1,\n",
    "                    \"sample\": i,\n",
    "                    \"index\": index\n",
    "                })\n",
    "\n",
    "    return [torch.cat(all_preds)], [torch.cat(all_y)], [val_meta_info]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0d4f3d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca5f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "# --- Training Config ---\n",
    "## 5-fold Cross Validation\n",
    "company_ids = df['ticker'].unique()\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "epochs = 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# ÂàùÂßãÂåñÂÑ≤Â≠òÊâÄÊúâ fold ÁöÑ loss\n",
    "all_train_losses_total, all_train_losses_count, all_train_losses_citation = [], [], []\n",
    "all_train_preds_total, all_train_targets_total, all_train_meta_info_total = [], [], []\n",
    "\n",
    "all_val_losses_count, all_val_losses_citation ,all_val_losses_total = [], [], []\n",
    "all_val_preds_total, all_val_targets_total, all_val_meta_info_total = [], [], []\n",
    "\n",
    "best_epoch_list = []\n",
    "\n",
    "for fold_id, (train_coms, test_coms) in enumerate(folds):\n",
    "    print(f\"\\n====== Fold {fold_id+1} ======\")\n",
    "\n",
    "    fold_train_preds_epochs, fold_train_targets_epochs, fold_train_meta_epochs = [], [], []\n",
    "    fold_val_preds_epochs, fold_val_targets_epochs, fold_val_meta_epochs = [], [], []\n",
    "    \n",
    "    # Dataset   \n",
    "    train_dataset = SlidingWindowDatasetMax5Flag(df, train_coms)\n",
    "    test_dataset = SlidingWindowDatasetMax5Flag(df, test_coms)\n",
    "\n",
    "    generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "    # DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=lambda x: x, generator=generator)\n",
    "    val_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=lambda x: x)\n",
    "\n",
    "    # Model\n",
    "    model = LSTM_MTL_Stepwise().to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    criterion = MSEPunishLoss(alpha=1.0, punish_mode='', return_each=True)\n",
    "\n",
    "    # ÂÑ≤Â≠òÊØèÂÄã epoch ÁöÑ lossÔºàÊØè fold ‰∏Ä‰ªΩÔºâ\n",
    "    train_loss_total_list, train_loss_count_list, train_loss_citation_list = [], [], []\n",
    "    val_loss_total_list, val_loss_count_list, val_loss_citation_list = [], [], []\n",
    "\n",
    "    # <-- Early Stopping ÂàùÂßãÂåñ -->\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    patience = 50\n",
    "    best_model_state = None\n",
    "    best_epoch = None  \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_losses, epoch_loss_count_all, epoch_loss_citation_all = [], [], []\n",
    "        train_preds, train_targets, train_meta_info = [], [], []\n",
    "        for batch_id, batch in enumerate(train_loader):\n",
    "            x_seqs, y_seqs, tickers, y_years, indices = zip(*batch)\n",
    "            lengths = torch.tensor([x.shape[0] for x in x_seqs]).to(device)\n",
    "            x_seqs = pad_sequence(x_seqs, batch_first=True).to(device)\n",
    "            y_seqs = torch.stack(y_seqs).to(device)\n",
    "\n",
    "            preds = model(x_seqs, lengths)\n",
    "\n",
    "            loss_total, loss_count, loss_citation = criterion(preds, y_seqs)\n",
    "            optimizer.zero_grad()\n",
    "            loss_total.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_losses.append(loss_total.item())\n",
    "            epoch_loss_count_all.append(loss_count)\n",
    "            epoch_loss_citation_all.append(loss_citation)\n",
    "\n",
    "            train_preds.append(preds.detach().cpu())\n",
    "            train_targets.append(y_seqs.detach().cpu())\n",
    "\n",
    "            for i, index in enumerate(indices):\n",
    "                train_meta_info.append({\n",
    "                    \"fold\": fold_id + 1,\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"batch\": batch_id + 1,\n",
    "                    \"sample\": i,\n",
    "                    \"index\": index\n",
    "                })\n",
    "\n",
    "            # # ‚úî ÊØèÂÄã batch Âç∞ loss„ÄÅpredictions„ÄÅtruth\n",
    "            # print(f\"[Fold {fold_id+1}][Epoch {epoch+1}][Train][Batch] Company: {tickers[0]} | Samples: {len(indices)}\")\n",
    "            # print(f\"  Total Loss: {loss_total.item():.4f} | Count Loss: {loss_count:.4f} | Citation Loss: {loss_citation:.4f}\")\n",
    "            # print(f\"  Predictions (expm1, rounded): {np.round(torch.expm1(preds).detach().cpu().numpy())}\")\n",
    "            # print(f\"  Ground truth (expm1, rounded): {np.round(torch.expm1(y_seqs).detach().cpu().numpy())}\")\n",
    "            # print(f\"  Indices: {indices}\")\n",
    "\n",
    "        avg_train_loss = np.mean(epoch_losses)\n",
    "        avg_train_count = np.mean(epoch_loss_count_all)\n",
    "        avg_train_citation = np.mean(epoch_loss_citation_all)\n",
    "\n",
    "        train_loss_total_list.append(avg_train_loss)\n",
    "        train_loss_count_list.append(avg_train_count)\n",
    "        train_loss_citation_list.append(avg_train_citation)\n",
    "\n",
    "        fold_train_meta_epochs.append(train_meta_info)\n",
    "        fold_train_preds_epochs.append(torch.cat(train_preds))\n",
    "        fold_train_targets_epochs.append(torch.cat(train_targets))\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_losses = []\n",
    "            val_loss_count_all = []\n",
    "            val_loss_citation_all = []\n",
    "            all_preds = []\n",
    "            all_y = []\n",
    "            val_meta_info = []  # <--- Êñ∞Â¢ûÔºöÊú¨ epoch ÁöÑ meta Ë≥áË®ä\n",
    "            for batch_id, batch in enumerate(val_loader):\n",
    "                x_seqs, y_seqs, tickers, y_years, indices = zip(*batch)\n",
    "                lengths = torch.tensor([x.shape[0] for x in x_seqs]).to(device)\n",
    "                x_seqs = pad_sequence(x_seqs, batch_first=True).to(device)\n",
    "                y_seqs = torch.stack(y_seqs).to(device)\n",
    "\n",
    "                preds = model(x_seqs, lengths)\n",
    "                loss_total, loss_count, loss_citation = criterion(preds, y_seqs)\n",
    "                \n",
    "                val_losses.append(loss_total.item())\n",
    "                val_loss_count_all.append(loss_count)\n",
    "                val_loss_citation_all.append(loss_citation)\n",
    "\n",
    "                all_preds.append(preds)\n",
    "                all_y.append(y_seqs)\n",
    "\n",
    "                # üíæ Êñ∞Â¢ûÔºöË®òÈåÑÊØè‰∏ÄÁ≠ÜÁöÑ fold / epoch / batch / sample index\n",
    "                for i, index in enumerate(indices):\n",
    "                    val_meta_info.append({\n",
    "                        \"fold\": fold_id + 1,\n",
    "                        \"epoch\": epoch + 1,\n",
    "                        \"batch\": batch_id + 1,\n",
    "                        \"sample\": i,\n",
    "                        \"index\": index\n",
    "                    })\n",
    "\n",
    "                # ‚úî ÊØèÂÄã batch Âç∞ loss„ÄÅpredictions„ÄÅtruth\n",
    "                print(f\"[Fold {fold_id+1}][Epoch {epoch+1}][Val][Batch] Company: {tickers[0]} | Samples: {len(indices)}\")\n",
    "                print(f\"  Total Loss: {loss_total.item():.4f} | Count Loss: {loss_count:.4f} | Citation Loss: {loss_citation:.4f}\")\n",
    "                print(f\"  Predictions (expm1, rounded): {np.round(torch.expm1(preds).detach().cpu().numpy())}\")\n",
    "                print(f\"  Ground truth (expm1, rounded): {np.round(torch.expm1(y_seqs).detach().cpu().numpy())}\")\n",
    "                print(f\"  Indices: {indices}\")\n",
    "\n",
    "            fold_val_preds_epochs.append(torch.cat(all_preds).cpu())\n",
    "            fold_val_targets_epochs.append(torch.cat(all_y).cpu())\n",
    "            fold_val_meta_epochs.append(val_meta_info)\n",
    "\n",
    "            avg_val_loss = np.mean(val_losses)\n",
    "            avg_val_count = np.mean(val_loss_count_all)\n",
    "            avg_val_citation = np.mean(val_loss_citation_all)\n",
    "\n",
    "            val_loss_total_list.append(avg_val_loss)\n",
    "            val_loss_count_list.append(avg_val_count)\n",
    "            val_loss_citation_list.append(avg_val_citation)\n",
    "\n",
    "            all_preds = torch.cat(all_preds)\n",
    "            all_y = torch.cat(all_y)\n",
    "\n",
    "            # ‚úî ÊØèÂÄã epoch ÊúÄÂæå summary\n",
    "            print(f\"[Fold {fold_id+1}][Epoch {epoch+1}] Summary\")\n",
    "            print(f\"  Train Avg Loss     -> Total: {avg_train_loss:.4f} | Count: {avg_train_count:.4f} | Citation: {avg_train_citation:.4f}\")\n",
    "            print(f\"  Validation Avg Loss-> Total: {avg_val_loss:.4f} | Count: {avg_val_count:.4f} | Citation: {avg_val_citation:.4f}\")\n",
    "\n",
    "        metrics = compute_metrics(all_preds, all_y)\n",
    "        for name, vals in metrics.items():\n",
    "            print(f\"  [{name.upper()}] Metrics -> MSE: {vals['MSE']:.4f} | MAE: {vals['MAE']:.4f} | \"\n",
    "                f\"RMSE: {vals['RMSE']:.4f} | SMAPE: {vals['SMAPE']:.2f}%\")\n",
    "\n",
    "        # <-- Early Stopping Âà§Êñ∑ -->\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = model.state_dict()\n",
    "            best_epoch = epoch\n",
    "            print(f\"  ‚úÖ Validation loss improved. Saving model.\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"  ‚ùå No improvement. Patience: {epochs_no_improve}/{patience}\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"  ‚èπ Early stopping triggered at epoch {epoch+1}. Best val_loss: {best_val_loss:.4f}\")\n",
    "            break\n",
    "        print(f\"  üîÑ Best model loaded from epoch {best_epoch}\")\n",
    "\n",
    "    # ÈÇÑÂéüÊúÄ‰Ω≥Ê®°ÂûãÁãÄÊÖãÔºàÂèØÈÅ∏Ôºâ\n",
    "    if best_model_state is not None:\n",
    "        # ÊúâÊó©ÂÅúÔºà‰ª£Ë°®‰∏≠ÈÄîÊúâÊúÄ‰Ω≥Ê®°ÂûãÔºâ\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(\"  üîÑ Best model loaded for final evaluation or saving.\")\n",
    "        fold_val_preds_epochs, fold_val_targets_epochs, fold_val_meta_epochs = evaluate_best_model(\n",
    "            model, val_loader, fold_id, best_epoch\n",
    "        )\n",
    "    else:\n",
    "        # Ê≤íÊúâÊó©ÂÅúÔºàË∑ëÊªø epochsÔºâÔºåÊ≠§ÊôÇÂ∞±‰øùÁïôÊúÄÂæå‰∏ÄËº™Ê®°ÂûãÔºåÁÖßÊ®£ evaluate\n",
    "        print(\"  ‚ö†Ô∏è No best model found. Using final epoch model for evaluation.\")\n",
    "        fold_val_preds_epochs, fold_val_targets_epochs, fold_val_meta_epochs = evaluate_best_model(\n",
    "            model, val_loader, fold_id, epoch  # Ê≠§ÊôÇ epoch Â∞±ÊòØÊúÄÂæå‰∏ÄËº™ index\n",
    "        )\n",
    "    \n",
    "    # ÊØèÂÄã fold ÂÑ≤Â≠òÈÄ≤Á∏ΩË°®‰∏≠\n",
    "    all_train_losses_total.append(train_loss_total_list)\n",
    "    all_train_losses_count.append(train_loss_count_list)\n",
    "    all_train_losses_citation.append(train_loss_citation_list)\n",
    "\n",
    "    all_train_preds_total.append(fold_train_preds_epochs)\n",
    "    all_train_targets_total.append(fold_train_targets_epochs)\n",
    "    all_train_meta_info_total.append(fold_train_meta_epochs)\n",
    "\n",
    "    all_val_losses_total.append(val_loss_total_list)\n",
    "    all_val_losses_count.append(val_loss_count_list)\n",
    "    all_val_losses_citation.append(val_loss_citation_list)\n",
    "\n",
    "    all_val_preds_total.append(fold_val_preds_epochs)\n",
    "    all_val_targets_total.append(fold_val_targets_epochs)\n",
    "    all_val_meta_info_total.append(fold_val_meta_epochs)\n",
    "\n",
    "    best_epoch_list.append(best_epoch + 1 if best_epoch is not None else epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79d2c32",
   "metadata": {},
   "source": [
    "## compute_sample_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c300de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sample_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    y_true, y_pred: shape [N, 2] numpy array, already expm1'd\n",
    "    ÂõûÂÇ≥ dictÔºåÂåÖÂê´ÊØèÁ≠ÜÊ®£Êú¨ÁöÑ MSE, MAE, RMSE, SMAPE for count & citation\n",
    "    \"\"\"\n",
    "    abs_error = np.abs(y_pred - y_true)\n",
    "    squared_error = (y_pred - y_true) ** 2\n",
    "    rmse_error = np.sqrt(squared_error)\n",
    "    smape_error = 2 * abs_error / (np.abs(y_pred) + np.abs(y_true) + 1e-8)\n",
    "\n",
    "    return {\n",
    "        \"count_MSE\": squared_error[:, 0],\n",
    "        \"count_MAE\": abs_error[:, 0],\n",
    "        \"count_RMSE\": rmse_error[:, 0],\n",
    "        \"count_SMAPE\": smape_error[:, 0],\n",
    "        \"citation_MSE\": squared_error[:, 1],\n",
    "        \"citation_MAE\": abs_error[:, 1],\n",
    "        \"citation_RMSE\": rmse_error[:, 1],\n",
    "        \"citation_SMAPE\": smape_error[:, 1],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac30a344",
   "metadata": {},
   "source": [
    "# Save validation result to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa32c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_summary_records, train_summary_records = [], []\n",
    "\n",
    "for fold_id in range(len(folds)):\n",
    "    fold_preds = all_val_preds_total[fold_id][0]\n",
    "    fold_targets = all_val_targets_total[fold_id][0]\n",
    "    fold_meta_info = all_val_meta_info_total[fold_id][0]\n",
    "\n",
    "    # inverse log1p\n",
    "    y_pred = torch.expm1(fold_preds).numpy()\n",
    "    y_true = torch.expm1(fold_targets).numpy()\n",
    "\n",
    "    metrics = compute_sample_metrics(y_true, y_pred)\n",
    "\n",
    "    for i, meta in enumerate(fold_meta_info):\n",
    "        val_summary_records.append({\n",
    "            \"fold\": meta[\"fold\"],\n",
    "            \"epoch\": meta[\"epoch\"],\n",
    "            \"batch\": meta[\"batch\"],\n",
    "            \"local_sample\": meta[\"sample\"],\n",
    "            \"index\": meta[\"index\"],\n",
    "            \"val_true_count\": round(y_true[i, 0], 4),\n",
    "            \"val_pred_count\": round(y_pred[i, 0], 4),\n",
    "            \"val_true_citation\": round(y_true[i, 1], 4),\n",
    "            \"val_pred_citation\": round(y_pred[i, 1], 4),\n",
    "            \"val_count_MSE\": round(metrics[\"count_MSE\"][i], 4),\n",
    "            \"val_count_MAE\": round(metrics[\"count_MAE\"][i], 4),\n",
    "            \"val_count_SMAPE\": round(metrics[\"count_SMAPE\"][i], 4),\n",
    "            \"val_citation_MSE\": round(metrics[\"citation_MSE\"][i], 4),\n",
    "            \"val_citation_MAE\": round(metrics[\"citation_MAE\"][i], 4),\n",
    "            \"val_citation_SMAPE\": round(metrics[\"citation_SMAPE\"][i], 4),\n",
    "            # train ÁïôÁ©∫\n",
    "            \"train_true_count\": np.nan,\n",
    "            \"train_pred_count\": np.nan,\n",
    "            \"train_true_citation\": np.nan,\n",
    "            \"train_pred_citation\": np.nan,\n",
    "            \"train_loss_total\": np.nan,\n",
    "            \"train_loss_count\": np.nan,\n",
    "            \"train_loss_citation\": np.nan,\n",
    "            \"train_count_MSE\": np.nan,\n",
    "            \"train_count_MAE\": np.nan,\n",
    "            \"train_count_SMAPE\": np.nan,\n",
    "            \"train_citation_MSE\": np.nan,\n",
    "            \"train_citation_MAE\": np.nan,\n",
    "            \"train_citation_SMAPE\": np.nan,\n",
    "        })\n",
    "\n",
    "    # === Training ===\n",
    "    for epoch in range(len(all_train_preds_total[fold_id])):\n",
    "        fold_preds = all_train_preds_total[fold_id][epoch].cpu()\n",
    "        fold_targets = all_train_targets_total[fold_id][epoch].cpu()\n",
    "        fold_meta_info = all_train_meta_info_total[fold_id][epoch]\n",
    "\n",
    "        y_pred = torch.expm1(fold_preds).numpy()\n",
    "        y_true = torch.expm1(fold_targets).numpy()\n",
    "\n",
    "        metrics = compute_sample_metrics(y_true, y_pred)\n",
    "\n",
    "        for i, meta in enumerate(fold_meta_info):\n",
    "            train_summary_records.append({\n",
    "                \"fold\": meta[\"fold\"],\n",
    "                \"epoch\": meta[\"epoch\"],\n",
    "                \"batch\": meta[\"batch\"],\n",
    "                \"local_sample\": meta[\"sample\"],\n",
    "                \"index\": meta[\"index\"],\n",
    "                # val ÁïôÁ©∫\n",
    "                \"val_true_count\": np.nan,\n",
    "                \"val_pred_count\": np.nan,\n",
    "                \"val_true_citation\": np.nan,\n",
    "                \"val_pred_citation\": np.nan,\n",
    "                \"val_loss_total\": np.nan,\n",
    "                \"val_loss_count\": np.nan,\n",
    "                \"val_loss_citation\": np.nan,\n",
    "                \"val_count_MSE\": np.nan,\n",
    "                \"val_count_MAE\": np.nan,\n",
    "                \"val_count_SMAPE\": np.nan,\n",
    "                \"val_citation_MSE\": np.nan,\n",
    "                \"val_citation_MAE\": np.nan,\n",
    "                \"val_citation_SMAPE\": np.nan,\n",
    "                # train ÁïôË≥áÊñô\n",
    "                \"train_true_count\": round(y_true[i, 0].item(), 4),\n",
    "                \"train_pred_count\": round(y_pred[i, 0].item(), 4),\n",
    "                \"train_true_citation\": round(y_true[i, 1].item(), 4),\n",
    "                \"train_pred_citation\": round(y_pred[i, 1].item(), 4),\n",
    "                \"train_count_MSE\": round(metrics[\"count_MSE\"][i].item(), 4),\n",
    "                \"train_count_MAE\": round(metrics[\"count_MAE\"][i].item(), 4),\n",
    "                \"train_count_SMAPE\": round(metrics[\"count_SMAPE\"][i].item(), 4),\n",
    "                \"train_citation_MSE\": round(metrics[\"citation_MSE\"][i].item(), 4),\n",
    "                \"train_citation_MAE\": round(metrics[\"citation_MAE\"][i].item(), 4),\n",
    "                \"train_citation_SMAPE\": round(metrics[\"citation_SMAPE\"][i].item(), 4),\n",
    "            })\n",
    "\n",
    "\n",
    "# ÂÑ≤Â≠ò CSV\n",
    "val_summary_df = pd.DataFrame(val_summary_records)\n",
    "train_summary_df = pd.DataFrame(train_summary_records)\n",
    "combined_df = pd.concat([val_summary_df, train_summary_df], ignore_index=True)\n",
    "val_summary_df.to_csv(\"../output/lstm_mtl_csr_embedding_v6_log_flag_val_detailed.csv\", index=False)\n",
    "combined_df.to_csv(\"../output/lstm_mtl_csr_embedding_v6_log_flag_train_val_detailed.csv\", index=False)\n",
    "print(\"‚úÖ Saved detailed validation results to 'train_val_detailed.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4801ac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n====== Final Summary: Each Fold's Avg Loss (per Y) ======\")\n",
    "for fold_id in range(len(folds)):\n",
    "    avg_train_count = np.mean(all_train_losses_count[fold_id])\n",
    "    avg_train_citation = np.mean(all_train_losses_citation[fold_id])\n",
    "    avg_val_count = np.mean(all_val_losses_count[fold_id])\n",
    "    avg_val_citation = np.mean(all_val_losses_citation[fold_id])\n",
    "    \n",
    "    print(f\"[Fold {fold_id+1}]\")\n",
    "    print(f\"  Train  -> Count Loss: {avg_train_count:.4f} | Citation Loss: {avg_train_citation:.4f}\")\n",
    "    print(f\"  Valid  -> Count Loss: {avg_val_count:.4f} | Citation Loss: {avg_val_citation:.4f}\")\n",
    "\n",
    "# ÂÖ®ÈÉ® fold Âä†Á∏ΩÂπ≥Âùá\n",
    "mean_train_count = np.mean([np.mean(x) for x in all_train_losses_count])\n",
    "mean_train_citation = np.mean([np.mean(x) for x in all_train_losses_citation])\n",
    "mean_val_count = np.mean([np.mean(x) for x in all_val_losses_count])\n",
    "mean_val_citation = np.mean([np.mean(x) for x in all_val_losses_citation])\n",
    "\n",
    "print(\"\\n====== Final Overall Avg Loss Across 5 Folds ======\")\n",
    "print(f\"Train  -> Count Loss: {mean_train_count:.4f} | Citation Loss: {mean_train_citation:.4f}\")\n",
    "print(f\"Valid  -> Count Loss: {mean_val_count:.4f} | Citation Loss: {mean_val_citation:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3f1eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Âêà‰ΩµÊâÄÊúâ fold ÁöÑÈ†êÊ∏¨Ëàá meta Ë≥áË®ä\n",
    "y_pred_all = torch.cat([torch.cat(fold) for fold in all_val_preds_total])\n",
    "y_true_all = torch.cat([torch.cat(fold) for fold in all_val_targets_total])\n",
    "meta_all = [meta for fold in all_val_meta_info_total for epoch in fold for meta in epoch]\n",
    "\n",
    "# ÈÇÑÂéüÂà∞ÂéüÂßãÁ©∫Èñì\n",
    "y_pred = torch.expm1(y_pred_all).numpy()\n",
    "y_true = torch.expm1(y_true_all).numpy()\n",
    "\n",
    "# Ë®àÁÆóÊØèÁ≠ÜÊ®£Êú¨ÁöÑË™§Â∑Æ\n",
    "abs_error = np.abs(y_pred - y_true)\n",
    "squared_error = (y_pred - y_true) ** 2\n",
    "rmse_error = np.sqrt(squared_error)\n",
    "smape = 2 * abs_error / (np.abs(y_pred) + np.abs(y_true) + 1e-8)\n",
    "\n",
    "# Âç∞Âá∫ÊâÄÊúâË≥áÊñôÔºàÂèØÊîπÊàê range(50) Ê∏õÂ∞ëËº∏Âá∫Ôºâ\n",
    "print(\"\\n===== Detailed Per-Sample Metric with Meta Info =====\")\n",
    "for i in range(len(y_true)):\n",
    "    meta = meta_all[i]\n",
    "    print(f\"\\n[Sample {i}] [Fold {meta['fold']}][Epoch {meta['epoch']}][Batch {meta['batch']}][Local Sample {meta['sample']}] Index: {meta['index']}\")\n",
    "    print(f\"  COUNT    -> True: {y_true[i, 0]:.2f}, Pred: {y_pred[i, 0]:.2f}\")\n",
    "    print(f\"              MSE: {squared_error[i, 0]:.4f}, MAE: {abs_error[i, 0]:.4f}, RMSE: {rmse_error[i, 0]:.4f}, SMAPE: {smape[i, 0]*100:.2f}%\")\n",
    "    print(f\"  CITATION -> True: {y_true[i, 1]:.2f}, Pred: {y_pred[i, 1]:.2f}\")\n",
    "    print(f\"              MSE: {squared_error[i, 1]:.4f}, MAE: {abs_error[i, 1]:.4f}, RMSE: {rmse_error[i, 1]:.4f}, SMAPE: {smape[i, 1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac9eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Âêà‰ΩµÈ†êÊ∏¨ËàáÊ®ôÁ±§\n",
    "y_pred_all = torch.cat([tensor for fold in all_val_preds_total for tensor in fold])\n",
    "y_true_all = torch.cat([tensor for fold in all_val_targets_total for tensor in fold])\n",
    "\n",
    "# ÈÇÑÂéüÂà∞ÂéüÂßãÁ©∫ÈñìÔºàexpm1Ôºâ\n",
    "y_pred = torch.expm1(y_pred_all).numpy()\n",
    "y_true = torch.expm1(y_true_all).numpy()\n",
    "\n",
    "# Ë®àÁÆóÊØè‰∏ÄÁ≠ÜÁöÑË™§Â∑Æ\n",
    "abs_error = np.abs(y_pred - y_true)            # shape: [N, 2]\n",
    "squared_error = (y_pred - y_true) ** 2         # shape: [N, 2]\n",
    "smape_numerator = 2 * abs_error\n",
    "smape_denominator = np.abs(y_pred) + np.abs(y_true) + 1e-8\n",
    "smape_error = smape_numerator / smape_denominator  # shape: [N, 2]\n",
    "\n",
    "# ÈÄêÁ≠ÜË®òÈåÑ\n",
    "count_metrics = {\n",
    "    \"MSE\": squared_error[:, 0],\n",
    "    \"MAE\": abs_error[:, 0],\n",
    "    \"RMSE\": np.sqrt(squared_error[:, 0]),\n",
    "    \"SMAPE\": smape_error[:, 0]\n",
    "}\n",
    "\n",
    "citation_metrics = {\n",
    "    \"MSE\": squared_error[:, 1],\n",
    "    \"MAE\": abs_error[:, 1],\n",
    "    \"RMSE\": np.sqrt(squared_error[:, 1]),\n",
    "    \"SMAPE\": smape_error[:, 1]\n",
    "}\n",
    "\n",
    "def show_top_k(metric_dict, metric_name, topk=10):\n",
    "    print(f\"\\n===== Top {topk} Samples by {metric_name} =====\")\n",
    "    for task, values in metric_dict.items():\n",
    "        top_idx = np.argsort(values)[-topk:][::-1]\n",
    "        print(f\"\\n>>> {metric_name} - {task.upper()}\")\n",
    "        for i in top_idx:\n",
    "            print(f\"[Sample {i}] {task}: {values[i]:.4f} | True: {y_true[i, 0 if task=='COUNT' else 1]:.2f}, Pred: {y_pred[i, 0 if task=='COUNT' else 1]:.2f}\")\n",
    "\n",
    "# ÂåÖË£ùÊàê COUNT / CITATION Ê®ôÁ±§\n",
    "count_named = {k: v for k, v in count_metrics.items()}\n",
    "citation_named = {k: v for k, v in citation_metrics.items()}\n",
    "\n",
    "# Â±ïÁ§∫ÂêÑÂÄã metric ‰∏≠Ë≤¢ÁçªÊúÄÂ§ßÁöÑÊ®£Êú¨\n",
    "for metric_name in [\"MSE\", \"MAE\", \"RMSE\", \"SMAPE\"]:\n",
    "    show_top_k({\n",
    "        \"COUNT\": count_named[metric_name],\n",
    "        \"CITATION\": citation_named[metric_name]\n",
    "    }, metric_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3ecc56",
   "metadata": {},
   "source": [
    "# Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea3f715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count Loss Learning Curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "for fold_id in range(5):\n",
    "    plt.plot(all_train_losses_count[fold_id], label=f\"Train Count - Fold {fold_id+1}\")\n",
    "    plt.plot(all_val_losses_count[fold_id], label=f\"Val Count - Fold {fold_id+1}\", linestyle='--')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Count Loss\")\n",
    "plt.title(\"Count Loss Learning Curve (Train vs. Validation)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Citation Loss Learning Curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "for fold_id in range(5):\n",
    "    plt.plot(all_train_losses_citation[fold_id], label=f\"Train Citation - Fold {fold_id+1}\")\n",
    "    plt.plot(all_val_losses_citation[fold_id], label=f\"Val Citation - Fold {fold_id+1}\", linestyle='--')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Citation Loss\")\n",
    "plt.title(\"Citation Loss Learning Curve (Train vs. Validation)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb85e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "for fold_id in range(5):\n",
    "    plt.plot(all_train_losses_count[fold_id], label=f\"Train Count - Fold {fold_id+1}\")\n",
    "    plt.plot(all_val_losses_count[fold_id], label=f\"Val Count - Fold {fold_id+1}\", linestyle='--')\n",
    "    plt.plot(all_train_losses_citation[fold_id], label=f\"Train Citation - Fold {fold_id+1}\")\n",
    "    plt.plot(all_val_losses_citation[fold_id], label=f\"Val Citation - Fold {fold_id+1}\", linestyle='--')\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Combined Loss Learning Curve (Train vs. Validation)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d44280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Âêà‰ΩµÊâÄÊúâÈ©óË≠âË≥áÊñô\n",
    "y_pred_all = torch.cat([tensor for fold in all_val_preds_total for tensor in fold])\n",
    "y_true_all = torch.cat([tensor for fold in all_val_targets_total for tensor in fold])\n",
    "\n",
    "# ÈÇÑÂéü log1p\n",
    "y_pred_all = np.expm1(y_pred_all)\n",
    "y_true_all = np.expm1(y_true_all)\n",
    "\n",
    "# Count Âúñ\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_true_all[:, 0], y_pred_all[:, 0], alpha=0.5)\n",
    "plt.plot([y_true_all[:, 0].min(), y_true_all[:, 0].max()],\n",
    "         [y_pred_all[:, 0].min(), y_pred_all[:, 0].max()], 'r--')\n",
    "plt.xlabel(\"Ground Truth (Count)\")\n",
    "plt.ylabel(\"Predictions (Count)\")\n",
    "plt.title(\"Predictions vs Ground Truth (Count) ‚Äì All Folds\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Citation Âúñ\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_true_all[:, 1], y_pred_all[:, 1], alpha=0.5)\n",
    "plt.plot([y_true_all[:, 1].min(), y_true_all[:, 1].max()],\n",
    "         [y_pred_all[:, 1].min(), y_pred_all[:, 1].max()], 'r--')\n",
    "plt.xlabel(\"Ground Truth (Citation)\")\n",
    "plt.ylabel(\"Predictions (Citation)\")\n",
    "plt.title(\"Predictions vs Ground Truth (Citation) ‚Äì All Folds\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9f26b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of samples: {y_true_all.shape[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csr_env",
   "language": "python",
   "name": "csr_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
