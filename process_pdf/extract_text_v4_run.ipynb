{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "660ecaa6-c434-4f16-8ba4-f4e73b41b4cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T07:51:20.952878Z",
     "start_time": "2025-02-17T07:51:20.947086Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = \"/usr/bin/tesseract\"\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from statistics import quantiles\n",
    "# from IPython.display import display\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c81f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_overlapping_regions(merged_regions, horizontal_threshold, vertical_threshold):\n",
    "    new_merged = []\n",
    "    while merged_regions:\n",
    "        region = merged_regions.pop(0)  # å–å‡ºç¬¬ä¸€å€‹å€åŸŸ\n",
    "        merged = False\n",
    "        for i, existing_region in enumerate(new_merged):\n",
    "            x1, y1, x2, y2, _, _, _, _, _ = existing_region\n",
    "            x, y, w, h = region[:4]\n",
    "\n",
    "            # horizontally_close = abs(x - x2) <= horizontal_threshold or abs(x1 - (x + w)) <= horizontal_threshold\n",
    "            # vertically_close = abs(y - y2) <= vertical_threshold or abs(y1 - (y + h)) <= vertical_threshold\n",
    "            overlap_horizontally = (x >= x1) and (x <= x2)\n",
    "            overlap_vertically = (y >= y1) and (y <= y2)\n",
    "\n",
    "            if overlap_horizontally and overlap_vertically:\n",
    "                # åˆä½µå€åŸŸ\n",
    "                new_merged[i][0] = min(new_merged[i][0], x)\n",
    "                new_merged[i][1] = min(new_merged[i][1], y)\n",
    "                new_merged[i][2] = max(new_merged[i][2], x + w)\n",
    "                new_merged[i][3] = max(new_merged[i][3], y + h)\n",
    "                new_merged[i][4] += region[4]\n",
    "                new_merged[i][5] += \" \" + region[5]\n",
    "                new_merged[i][6] += region[6]\n",
    "                new_merged[i][7] += region[7]\n",
    "                new_merged[i][8] += region[8]\n",
    "                merged = True\n",
    "                break\n",
    "\n",
    "        if not merged:\n",
    "            new_merged.append(region)\n",
    "\n",
    "    return new_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af7e0398-18fd-415a-9e86-f1f1b072d103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_pdf(pdf_path, output_image_path, density_threshold=15):\n",
    "    \n",
    "    os.makedirs(output_image_path, exist_ok=True)\n",
    "    pages = convert_from_path(pdf_path, dpi=300)\n",
    "    all_dense_regions = []\n",
    "\n",
    "    # éæ­·æŒ‡å®šé æ•¸ç¯„åœ\n",
    "    for page_i, page_image in enumerate(pages):\n",
    "        \n",
    "        # if page_i+1 < 39:\n",
    "        #     continue\n",
    "        # elif page_i+1 > 39:\n",
    "        #     break\n",
    "        \n",
    "        print(f\"\\n--- Processing Page {page_i + 1} ---\")\n",
    "        draw = ImageDraw.Draw(page_image)\n",
    "        # page_image = pages[page_i]\n",
    "\n",
    "        # æå–æ–‡å­—å€å¡Šè³‡è¨Š\n",
    "        data = pytesseract.image_to_data(page_image, output_type=pytesseract.Output.DICT)\n",
    "        # print(data['text'])\n",
    "        valid_indices = [\n",
    "            i for i in range(len(data['text']))\n",
    "            if data['text'][i].strip() and data['width'][i] > 0 and data['height'][i] > 0\n",
    "        ]\n",
    "\n",
    "        # è¨ˆç®—å‰25%çš„å¹³å‡å€¼\n",
    "        def trimmed_mean(values, trim_ratio=0.3):\n",
    "            if not values:\n",
    "                return 0\n",
    "            sorted_values = np.sort(values)\n",
    "            trim_count = int(len(sorted_values) * trim_ratio)\n",
    "            trimmed_values = sorted_values[:trim_count]\n",
    "            return np.mean(trimmed_values)\n",
    "        \n",
    "        def percentage(values, trim_ratio=0.8):\n",
    "            if not values:\n",
    "                return 0\n",
    "            sorted_values = np.sort(values)\n",
    "            trim_count = int(len(sorted_values) * trim_ratio)\n",
    "            trimmed_values = sorted_values[trim_count]\n",
    "            return trimmed_values\n",
    "\n",
    "        non_zero_widths = [w for w in data['width'] if w > 0]\n",
    "        non_zero_heights = [h for h in data['height'] if h > 0]\n",
    "        average_width = percentage(non_zero_widths, trim_ratio=0.5)\n",
    "        average_height = percentage(non_zero_heights)\n",
    "        # if valid_indices:\n",
    "        #     mean = sum(data['height'][i] for i in valid_indices) / len(valid_indices)\n",
    "        #     std = np.std([data['height'][i] for i in valid_indices])\n",
    "        #     average_height = mean + std\n",
    "        # else:\n",
    "        #     average_height = 0  # é¿å…é™¤ä»¥é›¶\n",
    "\n",
    "        horizontal_threshold = int(average_width) if not np.isnan(average_width) else 0\n",
    "        vertical_threshold = int(average_height) if not np.isnan(average_height) else 0\n",
    "\n",
    "        # print(f\"\\n--- Debug: Average Dimensions ---\")\n",
    "        # print(f\"Average Width: {average_width}\")\n",
    "        # print(f\"Average Height: {average_height}\")\n",
    "\n",
    "        # print(f\"\\n--- Debug: Thresholds ---\")\n",
    "        # print(f\"Horizontal Threshold: {horizontal_threshold}\")\n",
    "        # print(f\"Vertical Threshold: {vertical_threshold}\")\n",
    "\n",
    "#         if len(data['text']) < 300:\n",
    "#             continue\n",
    "\n",
    "        merged_regions = []\n",
    "        current_region = None\n",
    "\n",
    "        for i in range(len(data['text'])):\n",
    "            if data['text'][i].strip():\n",
    "                x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]\n",
    "                text = data['text'][i].strip()\n",
    "                text_length = len(text)\n",
    "                text_num = 1\n",
    "                sum_w = w\n",
    "                sum_h = h\n",
    "                updated = False\n",
    "\n",
    "                best_merge_value = np.inf \n",
    "                best_merge_region = None\n",
    "                for region in merged_regions[-3:]:\n",
    "                    x1, y1, x2, y2, total_text_length, all_text, total_text_num, sum_w, sum_h = region\n",
    "\n",
    "                    horizontally_close = abs(x - x2) <= horizontal_threshold or \\\n",
    "                                         abs(x1 - (x + w)) <= horizontal_threshold or \\\n",
    "                                         abs(x - x1) <= horizontal_threshold or \\\n",
    "                                         abs(x2 - (x + w)) <= horizontal_threshold\n",
    "                                         \n",
    "                    vertically_close = abs(y - y2) <= vertical_threshold or \\\n",
    "                                       abs(y1 - (y + h)) <= vertical_threshold or \\\n",
    "                                       abs(y - y1) <= vertical_threshold or \\\n",
    "                                       abs(y2 - (y + h)) <= vertical_threshold\n",
    "\n",
    "                    overlap_horizontally = (x >= x1) and (x <= x2) \n",
    "                    overlap_vertically = (y >= y1) and (y <= y2) \n",
    "                    \n",
    "                    # print(f'all_text: {all_text}, x1:{x1}, y1:{y1}, x2: {x2}, y2: {y2}')\n",
    "                    # print(f'text: {text}, x1:{x}, y1:{y}, x2: {x+w}, y2: {y+h}')\n",
    "                    # print(f'horizontally_dist: {abs(x - x2)}, {abs(x1 - (x + w))}, {abs(x - x1)}, {abs(x2 - (x + w))}')\n",
    "                    # print(f'horizontal_threshold: {horizontal_threshold}')\n",
    "                    # print(f'horizontally_close: {horizontally_close}')\n",
    "                    # print(f'vertically_dist: {abs(y - y2)}, {abs(y1 - (y + h))}, {abs(y - y1)}, {abs(y2 - (y + h))}')\n",
    "                    # print(f'vertical_threshold: {vertical_threshold}')\n",
    "                    # print(f'vertically_close: {vertically_close}')\n",
    "                    # print('-'*30)\n",
    "                    \n",
    "                    \n",
    "                    if (horizontally_close and vertically_close) or (overlap_horizontally and overlap_vertically):\n",
    "                        \n",
    "                        updated = True\n",
    "                        min_x = min(abs(x - x2), abs(x1 - (x + w)), abs(x - x1), abs(x2 - (x + w)))\n",
    "                        min_y = min(abs(y - y2), abs(y1 - (y + h)), abs(y - y1), abs(y2 - (y + h)))\n",
    "                        merge_value = min_x * min_y\n",
    "                        \n",
    "                        if overlap_horizontally and overlap_vertically:\n",
    "                            merge_value = 0\n",
    "                        \n",
    "                        if merge_value < best_merge_value:\n",
    "                            best_merge_value = merge_value\n",
    "                            best_merge_region = region\n",
    "                        \n",
    "                        # print(f'horizontally_close: {horizontally_close}')\n",
    "                        # print(f'vertically_close: {vertically_close}')\n",
    "                        # print(f'overlap_horizontally: {overlap_horizontally}, overlap_vertically: {overlap_vertically}')\n",
    "                        # print(f'all_text: {all_text}')\n",
    "                        # print(f'text_1: {text}')\n",
    "                        # print('-'*10)\n",
    "                        # print(f\"Merging Region: {region} with Text: {text}\")\n",
    "                \n",
    "                if updated and best_merge_region:\n",
    "                    best_merge_region[0] = min(best_merge_region[0], x)\n",
    "                    best_merge_region[1] = min(best_merge_region[1], y)\n",
    "                    best_merge_region[2] = max(best_merge_region[2], x + w)\n",
    "                    best_merge_region[3] = max(best_merge_region[3], y + h)\n",
    "                    best_merge_region[4] += text_length\n",
    "                    best_merge_region[5] += \" \" + text\n",
    "                    best_merge_region[6] += text_num\n",
    "                    best_merge_region[7] += sum_w\n",
    "                    best_merge_region[8] += sum_h\n",
    "                    # print(f\"Updated Region: {region}\")\n",
    "                    # break\n",
    "\n",
    "                elif not updated:\n",
    "                    current_region = [x, y, x + w, y + h, text_length, text, text_num, sum_w, sum_h]\n",
    "                    merged_regions.append(current_region)\n",
    "\n",
    "\n",
    "        # merged_regions = merge_overlapping_regions(merged_regions, horizontal_threshold, vertical_threshold)\n",
    "        \n",
    "        dense_regions = []\n",
    "        for region in merged_regions:\n",
    "            x1, y1, x2, y2, total_text_length, all_text, total_text_num, sum_w, sum_h = region\n",
    "            if total_text_num > density_threshold:\n",
    "                width = x2 - x1\n",
    "                height = y2 - y1\n",
    "                area = width * height\n",
    "                text_density = total_text_length / area if area > 0 else 0\n",
    "\n",
    "                if text_density >= 0:\n",
    "                # if text_density >= 0.0001:\n",
    "                    dense_regions.append({\n",
    "                        \"page\": page_i + 1,\n",
    "                        \"x1\": x1,\n",
    "                        \"y1\": y1,\n",
    "                        \"x2\": x2,\n",
    "                        \"y2\": y2,\n",
    "                        \"width\": width,\n",
    "                        \"height\": height,\n",
    "                        \"area\": area,\n",
    "                        \"total_text_length\": total_text_length,\n",
    "                        \"text_density\": text_density,\n",
    "                        \"all_text\": all_text,\n",
    "                        \"text_num\": total_text_num\n",
    "                    })\n",
    "\n",
    "        all_dense_regions.extend(dense_regions)\n",
    "        \n",
    "        for region in dense_regions:\n",
    "            x1, y1, x2, y2 = region[\"x1\"], region[\"y1\"], region[\"x2\"], region[\"y2\"]\n",
    "            draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)\n",
    "    \n",
    "        page_image.save(f'{output_image_path}/page_{page_i + 1}.jpg')\n",
    "\n",
    "    with open(f'{output_image_path}/dense_regions.json', 'w') as json_file:\n",
    "        json.dump(all_dense_regions, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0149d94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ è™•ç† PDF: /home/francia/research_hub/csr_project/CSR Reporting/NYSE/2020/NYSE_LLY_2020.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francia/anaconda3/envs/csr_env/lib/python3.11/site-packages/PIL/Image.py:3402: DecompressionBombWarning: Image size (96236904 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ ç„¡æ³•è™•ç† /home/francia/research_hub/csr_project/CSR Reporting/NYSE/2020/NYSE_LLY_2020.pdf: Image size (219234264 pixels) exceeds limit of 178956970 pixels, could be decompression bomb DOS attack.\n",
      "ğŸš€ è™•ç† PDF: /home/francia/research_hub/csr_project/CSR Reporting/NYSE/2018/NYSE_R_2018.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francia/anaconda3/envs/csr_env/lib/python3.11/site-packages/PIL/Image.py:3402: DecompressionBombWarning: Image size (117950040 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "/home/francia/anaconda3/envs/csr_env/lib/python3.11/site-packages/PIL/Image.py:3402: DecompressionBombWarning: Image size (116231400 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ ç„¡æ³•è™•ç† /home/francia/research_hub/csr_project/CSR Reporting/NYSE/2018/NYSE_R_2018.pdf: Image size (199206000 pixels) exceeds limit of 178956970 pixels, could be decompression bomb DOS attack.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# è¨­å®šè³‡æ–™å¤¾è·¯å¾‘\n",
    "pdf_folder = os.path.abspath(\"../CSR Reporting/NYSE/\")  # è½‰æ›ç‚ºçµ•å°è·¯å¾‘\n",
    "output_folder = os.path.abspath(\"../CSR_report_processed_v4/NYSE/\")  # è½‰æ›ç‚ºçµ•å°è·¯å¾‘\n",
    "\n",
    "# è¨­å®šè¦è™•ç†çš„ PDF æ•¸é‡\n",
    "num_files_to_process = 10000  # é€™è£¡å¯ä»¥æ”¹æˆä½ æƒ³è¦çš„æ•¸é‡\n",
    "\n",
    "# å–å¾— PDF æª”æ¡ˆæ¸…å–®\n",
    "pdf_files = []\n",
    "for root, _, files in os.walk(pdf_folder):  # os.walk éè¿´éæ­·æ‰€æœ‰å­è³‡æ–™å¤¾\n",
    "    for file in files:\n",
    "        if file.endswith(\".pdf\"):\n",
    "            pdf_files.append(os.path.abspath(os.path.join(root, file)))  # è½‰æ›ç‚ºçµ•å°è·¯å¾‘\n",
    "\n",
    "# ç¯©é¸æœªè™•ç†çš„ PDFï¼ˆå¦‚æœå°æ‡‰çš„è³‡æ–™å¤¾ä¸å­˜åœ¨æˆ–ç‚ºç©ºï¼‰\n",
    "pdf_files_to_process = []\n",
    "for pdf_file in pdf_files:\n",
    "    report_name = os.path.splitext(os.path.basename(pdf_file))[0]  # åªå–æª”åï¼Œå»æ‰å‰¯æª”å\n",
    "    output_path = os.path.join(output_folder, report_name)\n",
    "\n",
    "    # ç¢ºä¿è©²è¼¸å‡ºè³‡æ–™å¤¾ä¸å­˜åœ¨æˆ–ç‚ºç©º\n",
    "    if not os.path.exists(output_path) or not any(f.endswith(\".json\") for f in os.listdir(output_path)):\n",
    "        pdf_files_to_process.append(pdf_file)\n",
    "\n",
    "# é™åˆ¶è™•ç†æ•¸é‡\n",
    "pdf_files_to_process = pdf_files_to_process[:num_files_to_process]\n",
    "\n",
    "# ä¾åºè™•ç† PDF\n",
    "for pdf_file in pdf_files_to_process:\n",
    "    report_name = os.path.splitext(os.path.basename(pdf_file))[0]  # åªå–æª”åï¼Œå»æ‰å‰¯æª”å\n",
    "    output_image_path = os.path.join(output_folder, report_name)\n",
    "\n",
    "    # ç¢ºä¿è¼¸å‡ºè³‡æ–™å¤¾å­˜åœ¨\n",
    "    os.makedirs(output_image_path, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        print(f\"ğŸš€ è™•ç† PDF: {pdf_file}\")  # Debugï¼Œç¢ºèªè·¯å¾‘æ˜¯å¦æ­£ç¢º\n",
    "        process_pdf(pdf_file, output_image_path, density_threshold=0)\n",
    "        print(f\"âœ… æˆåŠŸè™•ç† PDF: {pdf_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ç„¡æ³•è™•ç† {pdf_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "795964aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 4843 folders are processed.\n"
     ]
    }
   ],
   "source": [
    "# calculate how many folders are in the CSR_report_processed_v4/NASDAQ folder\n",
    "output_folder = \"../CSR_report_processed_v4/NYSE/\"\n",
    "folder_count = 0\n",
    "for root, dirs, files in os.walk(output_folder):\n",
    "    for file in files:\n",
    "        if file.endswith(\".json\"):\n",
    "            folder_count += 1\n",
    "print(f\"Total {folder_count} folders are processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258bd01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csr_env",
   "language": "python",
   "name": "csr_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
