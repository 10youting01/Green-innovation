{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "660ecaa6-c434-4f16-8ba4-f4e73b41b4cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T07:51:20.952878Z",
     "start_time": "2025-02-17T07:51:20.947086Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = \"/usr/bin/tesseract\"\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from statistics import quantiles\n",
    "# from IPython.display import display\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c81f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_overlapping_regions(merged_regions, horizontal_threshold, vertical_threshold):\n",
    "    new_merged = []\n",
    "    while merged_regions:\n",
    "        region = merged_regions.pop(0)  # 取出第一個區域\n",
    "        merged = False\n",
    "        for i, existing_region in enumerate(new_merged):\n",
    "            x1, y1, x2, y2, _, _, _, _, _ = existing_region\n",
    "            x, y, w, h = region[:4]\n",
    "\n",
    "            # horizontally_close = abs(x - x2) <= horizontal_threshold or abs(x1 - (x + w)) <= horizontal_threshold\n",
    "            # vertically_close = abs(y - y2) <= vertical_threshold or abs(y1 - (y + h)) <= vertical_threshold\n",
    "            overlap_horizontally = (x >= x1) and (x <= x2)\n",
    "            overlap_vertically = (y >= y1) and (y <= y2)\n",
    "\n",
    "            if overlap_horizontally and overlap_vertically:\n",
    "                # 合併區域\n",
    "                new_merged[i][0] = min(new_merged[i][0], x)\n",
    "                new_merged[i][1] = min(new_merged[i][1], y)\n",
    "                new_merged[i][2] = max(new_merged[i][2], x + w)\n",
    "                new_merged[i][3] = max(new_merged[i][3], y + h)\n",
    "                new_merged[i][4] += region[4]\n",
    "                new_merged[i][5] += \" \" + region[5]\n",
    "                new_merged[i][6] += region[6]\n",
    "                new_merged[i][7] += region[7]\n",
    "                new_merged[i][8] += region[8]\n",
    "                merged = True\n",
    "                break\n",
    "\n",
    "        if not merged:\n",
    "            new_merged.append(region)\n",
    "\n",
    "    return new_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af7e0398-18fd-415a-9e86-f1f1b072d103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_pdf(pdf_path, output_image_path, density_threshold=15):\n",
    "    \n",
    "    os.makedirs(output_image_path, exist_ok=True)\n",
    "    pages = convert_from_path(pdf_path, dpi=300)\n",
    "    all_dense_regions = []\n",
    "\n",
    "    # 遍歷指定頁數範圍\n",
    "    for page_i, page_image in enumerate(pages):\n",
    "        \n",
    "        # if page_i+1 < 39:\n",
    "        #     continue\n",
    "        # elif page_i+1 > 39:\n",
    "        #     break\n",
    "        \n",
    "        print(f\"\\n--- Processing Page {page_i + 1} ---\")\n",
    "        draw = ImageDraw.Draw(page_image)\n",
    "        # page_image = pages[page_i]\n",
    "\n",
    "        # 提取文字區塊資訊\n",
    "        data = pytesseract.image_to_data(page_image, output_type=pytesseract.Output.DICT)\n",
    "        # print(data['text'])\n",
    "        valid_indices = [\n",
    "            i for i in range(len(data['text']))\n",
    "            if data['text'][i].strip() and data['width'][i] > 0 and data['height'][i] > 0\n",
    "        ]\n",
    "\n",
    "        # 計算前25%的平均值\n",
    "        def trimmed_mean(values, trim_ratio=0.3):\n",
    "            if not values:\n",
    "                return 0\n",
    "            sorted_values = np.sort(values)\n",
    "            trim_count = int(len(sorted_values) * trim_ratio)\n",
    "            trimmed_values = sorted_values[:trim_count]\n",
    "            return np.mean(trimmed_values)\n",
    "        \n",
    "        def percentage(values, trim_ratio=0.8):\n",
    "            if not values:\n",
    "                return 0\n",
    "            sorted_values = np.sort(values)\n",
    "            trim_count = int(len(sorted_values) * trim_ratio)\n",
    "            trimmed_values = sorted_values[trim_count]\n",
    "            return trimmed_values\n",
    "\n",
    "        non_zero_widths = [w for w in data['width'] if w > 0]\n",
    "        non_zero_heights = [h for h in data['height'] if h > 0]\n",
    "        average_width = percentage(non_zero_widths, trim_ratio=0.5)\n",
    "        average_height = percentage(non_zero_heights)\n",
    "        # if valid_indices:\n",
    "        #     mean = sum(data['height'][i] for i in valid_indices) / len(valid_indices)\n",
    "        #     std = np.std([data['height'][i] for i in valid_indices])\n",
    "        #     average_height = mean + std\n",
    "        # else:\n",
    "        #     average_height = 0  # 避免除以零\n",
    "\n",
    "        horizontal_threshold = int(average_width) if not np.isnan(average_width) else 0\n",
    "        vertical_threshold = int(average_height) if not np.isnan(average_height) else 0\n",
    "\n",
    "        # print(f\"\\n--- Debug: Average Dimensions ---\")\n",
    "        # print(f\"Average Width: {average_width}\")\n",
    "        # print(f\"Average Height: {average_height}\")\n",
    "\n",
    "        # print(f\"\\n--- Debug: Thresholds ---\")\n",
    "        # print(f\"Horizontal Threshold: {horizontal_threshold}\")\n",
    "        # print(f\"Vertical Threshold: {vertical_threshold}\")\n",
    "\n",
    "        # if len(data['text']) < 50:\n",
    "        #     continue\n",
    "\n",
    "        merged_regions = []\n",
    "        current_region = None\n",
    "\n",
    "        for i in range(len(data['text'])):\n",
    "            if data['text'][i].strip():\n",
    "                x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]\n",
    "                text = data['text'][i].strip()\n",
    "                text_length = len(text)\n",
    "                text_num = 1\n",
    "                sum_w = w\n",
    "                sum_h = h\n",
    "                updated = False\n",
    "\n",
    "                best_merge_value = np.inf \n",
    "                best_merge_region = None\n",
    "                for region in merged_regions[-3:]:\n",
    "                    x1, y1, x2, y2, total_text_length, all_text, total_text_num, sum_w, sum_h = region\n",
    "\n",
    "                    horizontally_close = abs(x - x2) <= horizontal_threshold or \\\n",
    "                                         abs(x1 - (x + w)) <= horizontal_threshold or \\\n",
    "                                         abs(x - x1) <= horizontal_threshold or \\\n",
    "                                         abs(x2 - (x + w)) <= horizontal_threshold\n",
    "                                         \n",
    "                    vertically_close = abs(y - y2) <= vertical_threshold or \\\n",
    "                                       abs(y1 - (y + h)) <= vertical_threshold or \\\n",
    "                                       abs(y - y1) <= vertical_threshold or \\\n",
    "                                       abs(y2 - (y + h)) <= vertical_threshold\n",
    "\n",
    "                    overlap_horizontally = (x >= x1) and (x <= x2) \n",
    "                    overlap_vertically = (y >= y1) and (y <= y2) \n",
    "                    \n",
    "                    # print(f'all_text: {all_text}, x1:{x1}, y1:{y1}, x2: {x2}, y2: {y2}')\n",
    "                    # print(f'text: {text}, x1:{x}, y1:{y}, x2: {x+w}, y2: {y+h}')\n",
    "                    # print(f'horizontally_dist: {abs(x - x2)}, {abs(x1 - (x + w))}, {abs(x - x1)}, {abs(x2 - (x + w))}')\n",
    "                    # print(f'horizontal_threshold: {horizontal_threshold}')\n",
    "                    # print(f'horizontally_close: {horizontally_close}')\n",
    "                    # print(f'vertically_dist: {abs(y - y2)}, {abs(y1 - (y + h))}, {abs(y - y1)}, {abs(y2 - (y + h))}')\n",
    "                    # print(f'vertical_threshold: {vertical_threshold}')\n",
    "                    # print(f'vertically_close: {vertically_close}')\n",
    "                    # print('-'*30)\n",
    "                    \n",
    "                    \n",
    "                    if (horizontally_close and vertically_close) or (overlap_horizontally and overlap_vertically):\n",
    "                        \n",
    "                        updated = True\n",
    "                        min_x = min(abs(x - x2), abs(x1 - (x + w)), abs(x - x1), abs(x2 - (x + w)))\n",
    "                        min_y = min(abs(y - y2), abs(y1 - (y + h)), abs(y - y1), abs(y2 - (y + h)))\n",
    "                        merge_value = min_x * min_y\n",
    "                        \n",
    "                        if overlap_horizontally and overlap_vertically:\n",
    "                            merge_value = 0\n",
    "                        \n",
    "                        if merge_value < best_merge_value:\n",
    "                            best_merge_value = merge_value\n",
    "                            best_merge_region = region\n",
    "                        \n",
    "                        # print(f'horizontally_close: {horizontally_close}')\n",
    "                        # print(f'vertically_close: {vertically_close}')\n",
    "                        # print(f'overlap_horizontally: {overlap_horizontally}, overlap_vertically: {overlap_vertically}')\n",
    "                        # print(f'all_text: {all_text}')\n",
    "                        # print(f'text_1: {text}')\n",
    "                        # print('-'*10)\n",
    "                        # print(f\"Merging Region: {region} with Text: {text}\")\n",
    "                \n",
    "                if updated and best_merge_region:\n",
    "                    best_merge_region[0] = min(best_merge_region[0], x)\n",
    "                    best_merge_region[1] = min(best_merge_region[1], y)\n",
    "                    best_merge_region[2] = max(best_merge_region[2], x + w)\n",
    "                    best_merge_region[3] = max(best_merge_region[3], y + h)\n",
    "                    best_merge_region[4] += text_length\n",
    "                    best_merge_region[5] += \" \" + text\n",
    "                    best_merge_region[6] += text_num\n",
    "                    best_merge_region[7] += sum_w\n",
    "                    best_merge_region[8] += sum_h\n",
    "                    # print(f\"Updated Region: {region}\")\n",
    "                    # break\n",
    "\n",
    "                elif not updated:\n",
    "                    current_region = [x, y, x + w, y + h, text_length, text, text_num, sum_w, sum_h]\n",
    "                    merged_regions.append(current_region)\n",
    "\n",
    "\n",
    "        # merged_regions = merge_overlapping_regions(merged_regions, horizontal_threshold, vertical_threshold)\n",
    "        \n",
    "        dense_regions = []\n",
    "        for region in merged_regions:\n",
    "            x1, y1, x2, y2, total_text_length, all_text, total_text_num, sum_w, sum_h = region\n",
    "            if total_text_num > density_threshold:\n",
    "                width = x2 - x1\n",
    "                height = y2 - y1\n",
    "                area = width * height\n",
    "                text_density = total_text_length / area if area > 0 else 0\n",
    "\n",
    "                # if text_density >= 0:\n",
    "                if text_density >= 0.0001:\n",
    "                    dense_regions.append({\n",
    "                        \"page\": page_i + 1,\n",
    "                        \"x1\": x1,\n",
    "                        \"y1\": y1,\n",
    "                        \"x2\": x2,\n",
    "                        \"y2\": y2,\n",
    "                        \"width\": width,\n",
    "                        \"height\": height,\n",
    "                        \"area\": area,\n",
    "                        \"total_text_length\": total_text_length,\n",
    "                        \"text_density\": text_density,\n",
    "                        \"all_text\": all_text,\n",
    "                        \"text_num\": total_text_num\n",
    "                    })\n",
    "\n",
    "        all_dense_regions.extend(dense_regions)\n",
    "        \n",
    "        for region in dense_regions:\n",
    "            x1, y1, x2, y2 = region[\"x1\"], region[\"y1\"], region[\"x2\"], region[\"y2\"]\n",
    "            draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)\n",
    "    \n",
    "        page_image.save(f'{output_image_path}/page_{page_i + 1}.jpg')\n",
    "\n",
    "    with open(f'{output_image_path}/dense_regions.json', 'w') as json_file:\n",
    "        json.dump(all_dense_regions, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eb19ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Page 1 ---\n",
      "\n",
      "--- Processing Page 2 ---\n",
      "\n",
      "--- Processing Page 3 ---\n",
      "\n",
      "--- Processing Page 4 ---\n",
      "\n",
      "--- Processing Page 5 ---\n",
      "\n",
      "--- Processing Page 6 ---\n",
      "\n",
      "--- Processing Page 7 ---\n",
      "\n",
      "--- Processing Page 8 ---\n",
      "\n",
      "--- Processing Page 9 ---\n",
      "\n",
      "--- Processing Page 10 ---\n",
      "\n",
      "--- Processing Page 11 ---\n",
      "\n",
      "--- Processing Page 12 ---\n",
      "\n",
      "--- Processing Page 13 ---\n",
      "\n",
      "--- Processing Page 14 ---\n",
      "\n",
      "--- Processing Page 15 ---\n",
      "\n",
      "--- Processing Page 16 ---\n",
      "\n",
      "--- Processing Page 17 ---\n",
      "\n",
      "--- Processing Page 18 ---\n",
      "\n",
      "--- Processing Page 19 ---\n",
      "\n",
      "--- Processing Page 20 ---\n",
      "\n",
      "--- Processing Page 21 ---\n",
      "\n",
      "--- Processing Page 22 ---\n",
      "\n",
      "--- Processing Page 23 ---\n",
      "\n",
      "--- Processing Page 24 ---\n",
      "\n",
      "--- Processing Page 25 ---\n",
      "\n",
      "--- Processing Page 26 ---\n",
      "\n",
      "--- Processing Page 27 ---\n",
      "\n",
      "--- Processing Page 28 ---\n",
      "\n",
      "--- Processing Page 29 ---\n",
      "\n",
      "--- Processing Page 30 ---\n",
      "\n",
      "--- Processing Page 31 ---\n",
      "\n",
      "--- Processing Page 32 ---\n",
      "\n",
      "--- Processing Page 33 ---\n",
      "\n",
      "--- Processing Page 34 ---\n",
      "\n",
      "--- Processing Page 35 ---\n",
      "\n",
      "--- Processing Page 36 ---\n",
      "\n",
      "--- Processing Page 37 ---\n",
      "\n",
      "--- Processing Page 38 ---\n",
      "\n",
      "--- Processing Page 39 ---\n",
      "\n",
      "--- Processing Page 40 ---\n",
      "\n",
      "--- Processing Page 41 ---\n",
      "\n",
      "--- Processing Page 42 ---\n",
      "\n",
      "--- Processing Page 43 ---\n",
      "\n",
      "--- Processing Page 44 ---\n",
      "\n",
      "--- Processing Page 45 ---\n",
      "\n",
      "--- Processing Page 46 ---\n",
      "\n",
      "--- Processing Page 47 ---\n",
      "\n",
      "--- Processing Page 48 ---\n",
      "\n",
      "--- Processing Page 49 ---\n",
      "\n",
      "--- Processing Page 50 ---\n",
      "\n",
      "--- Processing Page 51 ---\n",
      "\n",
      "--- Processing Page 52 ---\n",
      "\n",
      "--- Processing Page 53 ---\n",
      "\n",
      "--- Processing Page 54 ---\n",
      "\n",
      "--- Processing Page 55 ---\n",
      "\n",
      "--- Processing Page 56 ---\n",
      "\n",
      "--- Processing Page 57 ---\n",
      "\n",
      "--- Processing Page 58 ---\n",
      "\n",
      "--- Processing Page 59 ---\n",
      "\n",
      "--- Processing Page 60 ---\n",
      "\n",
      "--- Processing Page 61 ---\n",
      "\n",
      "--- Processing Page 62 ---\n",
      "\n",
      "--- Processing Page 63 ---\n",
      "\n",
      "--- Processing Page 64 ---\n",
      "\n",
      "--- Processing Page 65 ---\n",
      "\n",
      "--- Processing Page 66 ---\n",
      "\n",
      "--- Processing Page 67 ---\n",
      "\n",
      "--- Processing Page 68 ---\n",
      "\n",
      "--- Processing Page 69 ---\n",
      "\n",
      "--- Processing Page 70 ---\n",
      "\n",
      "--- Processing Page 71 ---\n",
      "\n",
      "--- Processing Page 72 ---\n",
      "\n",
      "--- Processing Page 73 ---\n",
      "\n",
      "--- Processing Page 74 ---\n",
      "\n",
      "--- Processing Page 75 ---\n",
      "\n",
      "--- Processing Page 76 ---\n",
      "\n",
      "--- Processing Page 77 ---\n",
      "\n",
      "--- Processing Page 1 ---\n",
      "\n",
      "--- Processing Page 2 ---\n",
      "\n",
      "--- Processing Page 3 ---\n",
      "\n",
      "--- Processing Page 4 ---\n",
      "\n",
      "--- Processing Page 5 ---\n",
      "\n",
      "--- Processing Page 6 ---\n",
      "\n",
      "--- Processing Page 7 ---\n",
      "\n",
      "--- Processing Page 8 ---\n",
      "\n",
      "--- Processing Page 9 ---\n",
      "\n",
      "--- Processing Page 10 ---\n",
      "\n",
      "--- Processing Page 11 ---\n",
      "\n",
      "--- Processing Page 12 ---\n",
      "\n",
      "--- Processing Page 13 ---\n",
      "\n",
      "--- Processing Page 14 ---\n",
      "\n",
      "--- Processing Page 15 ---\n",
      "\n",
      "--- Processing Page 16 ---\n",
      "\n",
      "--- Processing Page 17 ---\n",
      "\n",
      "--- Processing Page 18 ---\n",
      "\n",
      "--- Processing Page 19 ---\n",
      "\n",
      "--- Processing Page 20 ---\n",
      "\n",
      "--- Processing Page 21 ---\n",
      "\n",
      "--- Processing Page 22 ---\n",
      "\n",
      "--- Processing Page 23 ---\n",
      "\n",
      "--- Processing Page 24 ---\n",
      "\n",
      "--- Processing Page 25 ---\n",
      "\n",
      "--- Processing Page 26 ---\n",
      "\n",
      "--- Processing Page 27 ---\n",
      "\n",
      "--- Processing Page 28 ---\n",
      "\n",
      "--- Processing Page 29 ---\n",
      "\n",
      "--- Processing Page 30 ---\n",
      "\n",
      "--- Processing Page 31 ---\n",
      "\n",
      "--- Processing Page 32 ---\n",
      "\n",
      "--- Processing Page 33 ---\n",
      "\n",
      "--- Processing Page 34 ---\n",
      "\n",
      "--- Processing Page 35 ---\n",
      "\n",
      "--- Processing Page 36 ---\n",
      "\n",
      "--- Processing Page 37 ---\n",
      "\n",
      "--- Processing Page 38 ---\n",
      "\n",
      "--- Processing Page 39 ---\n",
      "\n",
      "--- Processing Page 40 ---\n",
      "\n",
      "--- Processing Page 41 ---\n",
      "\n",
      "--- Processing Page 42 ---\n",
      "\n",
      "--- Processing Page 43 ---\n",
      "\n",
      "--- Processing Page 44 ---\n",
      "\n",
      "--- Processing Page 45 ---\n",
      "\n",
      "--- Processing Page 46 ---\n",
      "\n",
      "--- Processing Page 47 ---\n",
      "\n",
      "--- Processing Page 48 ---\n",
      "\n",
      "--- Processing Page 49 ---\n",
      "\n",
      "--- Processing Page 50 ---\n",
      "\n",
      "--- Processing Page 51 ---\n",
      "\n",
      "--- Processing Page 52 ---\n",
      "\n",
      "--- Processing Page 53 ---\n",
      "\n",
      "--- Processing Page 54 ---\n",
      "\n",
      "--- Processing Page 55 ---\n",
      "\n",
      "--- Processing Page 56 ---\n",
      "\n",
      "--- Processing Page 57 ---\n",
      "\n",
      "--- Processing Page 58 ---\n",
      "\n",
      "--- Processing Page 59 ---\n",
      "\n",
      "--- Processing Page 60 ---\n",
      "\n",
      "--- Processing Page 61 ---\n",
      "\n",
      "--- Processing Page 1 ---\n",
      "\n",
      "--- Processing Page 2 ---\n",
      "\n",
      "--- Processing Page 3 ---\n",
      "\n",
      "--- Processing Page 4 ---\n",
      "\n",
      "--- Processing Page 5 ---\n",
      "\n",
      "--- Processing Page 6 ---\n",
      "\n",
      "--- Processing Page 7 ---\n",
      "\n",
      "--- Processing Page 8 ---\n",
      "\n",
      "--- Processing Page 9 ---\n",
      "\n",
      "--- Processing Page 10 ---\n",
      "\n",
      "--- Processing Page 11 ---\n",
      "\n",
      "--- Processing Page 12 ---\n",
      "\n",
      "--- Processing Page 13 ---\n",
      "\n",
      "--- Processing Page 14 ---\n",
      "\n",
      "--- Processing Page 15 ---\n",
      "\n",
      "--- Processing Page 16 ---\n",
      "\n",
      "--- Processing Page 17 ---\n",
      "\n",
      "--- Processing Page 18 ---\n",
      "\n",
      "--- Processing Page 19 ---\n",
      "\n",
      "--- Processing Page 20 ---\n",
      "\n",
      "--- Processing Page 21 ---\n",
      "\n",
      "--- Processing Page 22 ---\n",
      "\n",
      "--- Processing Page 23 ---\n",
      "\n",
      "--- Processing Page 24 ---\n",
      "\n",
      "--- Processing Page 25 ---\n",
      "\n",
      "--- Processing Page 26 ---\n",
      "\n",
      "--- Processing Page 27 ---\n",
      "\n",
      "--- Processing Page 28 ---\n",
      "\n",
      "--- Processing Page 29 ---\n",
      "\n",
      "--- Processing Page 30 ---\n",
      "\n",
      "--- Processing Page 31 ---\n",
      "\n",
      "--- Processing Page 32 ---\n",
      "\n",
      "--- Processing Page 33 ---\n",
      "\n",
      "--- Processing Page 34 ---\n",
      "\n",
      "--- Processing Page 35 ---\n",
      "\n",
      "--- Processing Page 36 ---\n",
      "\n",
      "--- Processing Page 37 ---\n",
      "\n",
      "--- Processing Page 38 ---\n",
      "\n",
      "--- Processing Page 39 ---\n",
      "\n",
      "--- Processing Page 40 ---\n",
      "\n",
      "--- Processing Page 41 ---\n",
      "\n",
      "--- Processing Page 42 ---\n",
      "\n",
      "--- Processing Page 43 ---\n",
      "\n",
      "--- Processing Page 44 ---\n",
      "\n",
      "--- Processing Page 45 ---\n",
      "\n",
      "--- Processing Page 46 ---\n",
      "\n",
      "--- Processing Page 47 ---\n",
      "\n",
      "--- Processing Page 48 ---\n",
      "\n",
      "--- Processing Page 49 ---\n",
      "\n",
      "--- Processing Page 50 ---\n",
      "\n",
      "--- Processing Page 51 ---\n",
      "\n",
      "--- Processing Page 52 ---\n",
      "\n",
      "--- Processing Page 53 ---\n",
      "\n",
      "--- Processing Page 54 ---\n",
      "\n",
      "--- Processing Page 55 ---\n",
      "\n",
      "--- Processing Page 56 ---\n",
      "\n",
      "--- Processing Page 57 ---\n",
      "\n",
      "--- Processing Page 58 ---\n",
      "\n",
      "--- Processing Page 59 ---\n",
      "\n",
      "--- Processing Page 60 ---\n",
      "\n",
      "--- Processing Page 61 ---\n",
      "\n",
      "--- Processing Page 62 ---\n",
      "\n",
      "--- Processing Page 63 ---\n",
      "\n",
      "--- Processing Page 64 ---\n",
      "\n",
      "--- Processing Page 65 ---\n",
      "\n",
      "--- Processing Page 66 ---\n",
      "\n",
      "--- Processing Page 67 ---\n",
      "\n",
      "--- Processing Page 68 ---\n",
      "\n",
      "--- Processing Page 69 ---\n",
      "\n",
      "--- Processing Page 70 ---\n",
      "\n",
      "--- Processing Page 1 ---\n",
      "\n",
      "--- Processing Page 2 ---\n",
      "\n",
      "--- Processing Page 3 ---\n",
      "\n",
      "--- Processing Page 4 ---\n",
      "\n",
      "--- Processing Page 5 ---\n",
      "\n",
      "--- Processing Page 6 ---\n",
      "\n",
      "--- Processing Page 7 ---\n",
      "\n",
      "--- Processing Page 8 ---\n",
      "\n",
      "--- Processing Page 9 ---\n",
      "\n",
      "--- Processing Page 10 ---\n",
      "\n",
      "--- Processing Page 11 ---\n",
      "\n",
      "--- Processing Page 12 ---\n",
      "\n",
      "--- Processing Page 13 ---\n",
      "\n",
      "--- Processing Page 14 ---\n",
      "\n",
      "--- Processing Page 15 ---\n",
      "\n",
      "--- Processing Page 16 ---\n",
      "\n",
      "--- Processing Page 17 ---\n",
      "\n",
      "--- Processing Page 18 ---\n",
      "\n",
      "--- Processing Page 19 ---\n",
      "\n",
      "--- Processing Page 20 ---\n",
      "\n",
      "--- Processing Page 21 ---\n",
      "\n",
      "--- Processing Page 22 ---\n",
      "\n",
      "--- Processing Page 23 ---\n",
      "\n",
      "--- Processing Page 24 ---\n",
      "\n",
      "--- Processing Page 25 ---\n",
      "\n",
      "--- Processing Page 26 ---\n",
      "\n",
      "--- Processing Page 27 ---\n",
      "\n",
      "--- Processing Page 28 ---\n",
      "\n",
      "--- Processing Page 29 ---\n",
      "\n",
      "--- Processing Page 30 ---\n",
      "\n",
      "--- Processing Page 31 ---\n",
      "\n",
      "--- Processing Page 32 ---\n",
      "\n",
      "--- Processing Page 33 ---\n",
      "\n",
      "--- Processing Page 34 ---\n",
      "\n",
      "--- Processing Page 35 ---\n",
      "\n",
      "--- Processing Page 36 ---\n",
      "\n",
      "--- Processing Page 37 ---\n",
      "\n",
      "--- Processing Page 38 ---\n",
      "\n",
      "--- Processing Page 39 ---\n",
      "\n",
      "--- Processing Page 40 ---\n",
      "\n",
      "--- Processing Page 41 ---\n",
      "\n",
      "--- Processing Page 42 ---\n",
      "\n",
      "--- Processing Page 43 ---\n",
      "\n",
      "--- Processing Page 44 ---\n",
      "\n",
      "--- Processing Page 45 ---\n",
      "\n",
      "--- Processing Page 46 ---\n",
      "\n",
      "--- Processing Page 47 ---\n",
      "\n",
      "--- Processing Page 48 ---\n",
      "\n",
      "--- Processing Page 49 ---\n",
      "\n",
      "--- Processing Page 50 ---\n",
      "\n",
      "--- Processing Page 51 ---\n",
      "\n",
      "--- Processing Page 52 ---\n",
      "\n",
      "--- Processing Page 53 ---\n",
      "\n",
      "--- Processing Page 54 ---\n"
     ]
    }
   ],
   "source": [
    "for report_namne in ['NASDAQ_ADI_2019', 'NASDAQ_TEAM_2021', 'NASDAQ_VRTU_2020_2021', 'NASDAQ_CRTO_2018']:\n",
    "    pdf_path = f\"../CSR Reporting/NASDAQ/{report_namne}.pdf\"  # 替換為您的 PDF 路徑\n",
    "    output_image_path = f\"../CSR_report_processed_re_v5/NASDAQ/{report_namne}\"\n",
    "    output_file_path = f\"../CSR_report_processed_re_v5/NASDAQ/{report_namne}/{report_namne}.json\"\n",
    "    process_pdf(pdf_path, output_image_path, density_threshold=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
